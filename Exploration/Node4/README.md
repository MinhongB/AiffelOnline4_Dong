# Quest4

아이펠캠퍼스 온라인4기 피어코드리뷰
.
- 코더 : 김동규
- 리뷰어 : 임지혜
-------------------------------------------------- -----------

PRT(PeerReviewTemplate)

- [O] 코드가 정상적으로 동작하고 주어진 문제를 해결했나요?
> - 코드가 에러없이 작동할 것으로 예상되며, 결론을 마지막에 잘 정리해주셨음
> - 3가지 모델(RNN, 1D CNN, GlobalMaxPooling1D기반) 구축 및 작동완료
```
('매우', 0.8843027353286743)|('약자', 0.8051141500473022)|('단체', 0.7845001220703125)|('취미', 0.5857348442077637)
('넘', 0.8789970278739929)|('정말', 0.7905513048171997)|('사후', 0.7741118669509888)|('유머', 0.5140613913536072)
('이해도', 0.8782033920288086)|('구요', 0.7825247049331665)|('갤', 0.7567523717880249)|('매력', 0.5105490684509277)
('가치', 0.8582432866096497)|('중심', 0.7659239172935486)|('권력', 0.7354912161827087)|('흥미', 0.4988338351249695)
('제외', 0.8562479019165039)|('녹', 0.7606545686721802)|('신체', 0.7154641151428223)|('공짜', 0.4960595667362213)
('공감', 0.8499742746353149)|('툭툭', 0.7492883205413818)|('아마', 0.7075228691101074)|('일자리', 0.49294644594192505)
('이미숙', 0.8411532044410706)|('커', 0.7468106746673584)|('일제', 0.6915094256401062)|('즐거움', 0.48700767755508423)
('표정', 0.8410723209381104)|('흥겹', 0.7396458387374878)|('추격전', 0.6897620558738708)|('비애', 0.4836210310459137)
('매력', 0.8393557071685791)|('가능', 0.7390083074569702)|('단면', 0.6868882179260254)|('관객', 0.48286449909210205)
('긴장감', 0.8345389366149902)|('삐', 0.7200238704681396)|('볼걸', 0.6830145716667175)|('향수', 0.4823310971260071)
위는 주제어는 각각 '재미'를 주제로 유사 단어를 추출한 결과이다. 기본적으로 파인튜닝한 쪽이 사람이 봤을 때 유사한 단어가 많다.

대표적으로 '유머', '매력', '취미', 그리고 '흥미'는 재미와 관련된 단어라는 것을 직관적으로 알 수 있다. 하지만 '메우'와 '넘'은 같이 자주 쓰이지만, '이해도' '가치', '약자' (넌.. 왜..), '갤' (DC 인사이드?) 등은 왜 있는지 연관성을 알 수 없다.

또한 이 페이지에서 나타나지 않지만, 위의 3개의 모델에는 85%를 넘기 위한 노력이 많이 들어갔으나, 한국어 Word2Vec을 사용한 경우 적은 노력으로 85% 이상의 정확도를 달성할 수 있었다.

이를 통해, 워드 임베딩이 모델 성능과 평가 지표에 주는 영향력을 볼 수 있었다.
```

- [O] 주석을 보고 작성자의 코드가 이해되었나요?
>모델선언부터 학습수행 평가까지 흐름을 주석으로 잘 정리해주심
```
# 모델 컴파일
model1.compile(optimizer='adam',
              loss='binary_crossentropy',
              metrics=['accuracy'])
              
epochs=5

# 학습 수행
history = model1.fit(partial_X_train,
                    partial_y_train,
                    epochs=epochs,
                    batch_size=512,
                    validation_data=(X_val, y_val),
                    verbose=1)

# 평가
results = model1.evaluate(X_test,  y_test, verbose=2)
```

- ['X] 코드가 에러를 유발할 가능성이 있나요?
>에러 없이 잘 작동할 것으로 판단됨



- [O] 코드 작성자가 코드를 제대로 이해하고 작성했나요? (직접 인터뷰해보기)
>dropout등 여러 기법을 사용해 오버피팅을 막기 위한 코드 작성
```
#RNN 기반 모델 구성
model1 = keras.Sequential()
model1.add(keras.layers.Embedding(vocab_size, word_vector_dim, input_shape=(None,)))
model1.add(keras.layers.LSTM(128))
model1.add(keras.layers.Dense(32, activation='relu'))
model1.add(keras.layers.Dropout(0.5))
model1.add(keras.layers.Dense(8, activation='relu'))
model1.add(keras.layers.Dropout(0.5))
model1.add(keras.layers.Dense(1, activation='sigmoid'))
```

- [O] 코드가 간결한가요?
>데이터 전처리 시에 토크나이징과 불용어를 제거하는 함수를 구축해 중복함수 정리
```
def load_data(train_data, test_data):
    def tokenize_and_remove_stopword(data):
```

>모델학습부터 그래프 출력까지 자동화한 test_pipeline을 선언해서 코드 간결화시킴
```
def test_pipeline(model, X_train, y_train, X_val, y_val, X_test, y_test, epochs=20, batch_size=512):
```

----------------------------------------------

참고 링크 및 코드 개선
- 코드 리뷰 시 참고한 링크가 있다면 링크와 간략한 설명을 첨부합니다.
- 코드 리뷰를 통해 개선한 코드가 있다면 코드와 간략한 설명을 첨부합니다.
